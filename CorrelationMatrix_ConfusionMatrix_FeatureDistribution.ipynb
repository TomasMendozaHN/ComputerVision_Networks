{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CorrelationMatrix_ConfusionMatrix_FeatureDistribution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOH9TiPrWIcJMKx4AB/t8pU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomasMendozaHN/ComputerVision_Networks/blob/master/CorrelationMatrix_ConfusionMatrix_FeatureDistribution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFHePkG_CBEb"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle #mkdir = make directory\n",
        "!cp kaggle.json ~/.kaggle/  # cp = copy\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download titanic"
      ],
      "metadata": {
        "id": "SdeGZQ4kFfGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip titanic.zip"
      ],
      "metadata": {
        "id": "6yRL4EdNFLiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "trainData = pd.read_csv(\"train.csv\")\n",
        "trainData.head()"
      ],
      "metadata": {
        "id": "FR301tNTF49z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill NaN values with 0\n",
        "trainData = trainData.fillna(0)\n",
        "\n",
        "# Drop useless data\n",
        "trainData = trainData.drop(['Name', 'Ticket'], axis='columns')"
      ],
      "metadata": {
        "id": "mnSv4fqlKNLW"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainData.head()"
      ],
      "metadata": {
        "id": "XBBSE7sAMGbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Data"
      ],
      "metadata": {
        "id": "FQgiz-EYLgkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainData.hist(figsize=(16,8))"
      ],
      "metadata": {
        "id": "_BCyqM_0LfXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainData.groupby('Survived').hist(figsize=(16,8))"
      ],
      "metadata": {
        "id": "aKtdtdSzLlgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Correlations"
      ],
      "metadata": {
        "id": "e-ZEqH6vOJEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize']=(18,14)\n",
        "import seaborn as sns\n",
        "corrMatrix = trainData.corr()\n",
        "sns.heatmap(corrMatrix, annot=True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sADis4myOIiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Numerical to Categorical"
      ],
      "metadata": {
        "id": "2Crf2pzhJqmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainData = pd.get_dummies(trainData)\n",
        "trainData.head()"
      ],
      "metadata": {
        "id": "6ZmxJenYJufV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainY = trainData['Survived']\n",
        "trainX = trainData.drop(['Survived'], axis='columns')\n",
        "trainX, trainY"
      ],
      "metadata": {
        "id": "SMC5eqzcHAAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataframes to numpy arrays\n",
        "import numpy as np\n",
        "trainX, trainY = np.array(trainX), np.array(trainY)\n",
        "trainX.shape, trainY.shape"
      ],
      "metadata": {
        "id": "nw-oPlvbSBDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "trainX, trainY = shuffle(trainX, trainY, random_state=0)"
      ],
      "metadata": {
        "id": "A9WwEKhjSRcU"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainX, testX, trainY, testY = train_test_split(trainX, trainY, test_size=0.30, random_state=42)\n",
        "trainX.shape, testX.shape"
      ],
      "metadata": {
        "id": "IiRXlYu1cywd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define MLP model"
      ],
      "metadata": {
        "id": "fDGaXq0XPVxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch.nn import LogSoftmax\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_fc = nn.Linear(input_dim, 128)\n",
        "        self.hidden_fc = nn.Linear(128, 128)\n",
        "        self.hidden_fc2 = nn.Linear(128, 128)\n",
        "        self.hidden_fc3 = nn.Linear(128, 128)\n",
        "        self.hidden_fc4 = nn.Linear(128, 128)\n",
        "        self.hidden_fc5 = nn.Linear(128, 128)\n",
        "        self.output_fc6 = nn.Linear(128, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_1 = F.relu(self.input_fc(x))\n",
        "        h_2 = F.relu(self.hidden_fc(h_1))\n",
        "        h_3 = F.relu(self.hidden_fc2(h_2))\n",
        "        h_4 = F.relu(self.hidden_fc3(h_3))\n",
        "        h_5 = F.relu(self.hidden_fc4(h_4))\n",
        "        h_6 = F.relu(self.hidden_fc5(h_5))\n",
        "        y_pred = self.output_fc6(h_6)\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "101pToT-LvoZ"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MLP(160,2)"
      ],
      "metadata": {
        "id": "_uXwuQyhNd16"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "# initialize our optimizer and loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "rZIGQnFPRq5Y"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "hist_loss = []\n",
        "\n",
        "for epoch in tqdm.tqdm(range(2000)):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  X = torch.from_numpy(trainX).type(torch.FloatTensor)\n",
        "  Y = torch.from_numpy(trainY).type(torch.LongTensor)\n",
        "\n",
        "  outputs = net(X)\n",
        "\n",
        "  loss = loss_function(outputs, Y)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  hist_loss.append(loss.detach().cpu().numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "dmU5SDwyR3wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = (14,6)\n",
        "plt.plot(hist_loss)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QAnaJiv6UZli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test!"
      ],
      "metadata": {
        "id": "WIQZj9bYbau6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim=True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ],
      "metadata": {
        "id": "K7RTUHzTdkWI"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "\n",
        "X = torch.from_numpy(testX).type(torch.FloatTensor)\n",
        "Y = torch.from_numpy(testY).type(torch.LongTensor)\n",
        "\n",
        "y_pred = net(X)\n",
        "\n",
        "probs = F.softmax(y_pred, dim=-1)\n",
        "pred_labels = torch.argmax(probs, 1).detach().numpy()\n",
        "\n",
        "loss = loss_function(y_pred, Y)\n",
        "\n",
        "acc = calculate_accuracy(y_pred, Y)\n",
        "acc = float(acc.detach().numpy())\n",
        "print(f\"The accuracy of your model is = {round(acc,4)*100}%\")"
      ],
      "metadata": {
        "id": "6tPCV7EZcgL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation Matrix"
      ],
      "metadata": {
        "id": "xEEzc0xneiA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def plot_confusion_matrix(labels, pred_labels):\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    cm = metrics.confusion_matrix(labels, pred_labels)\n",
        "    cm = metrics.ConfusionMatrixDisplay(cm, display_labels=range(10))\n",
        "    cm.plot(values_format='d', cmap='Blues', ax=ax)"
      ],
      "metadata": {
        "id": "v3k6oDtEf1NI"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(testY, pred_labels)"
      ],
      "metadata": {
        "id": "UblEEgnld7FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YIm5IjBRhadC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}